{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "831c2fe0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "831c2fe0",
    "outputId": "6de70e2e-9ef2-41de-9907-0e715285e33f"
   },
   "outputs": [],
   "source": [
    "train_df = []\n",
    "train = []\n",
    "highlights = []\n",
    "new_train = []\n",
    "new_highlights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "KTWfkfGV4zZE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTWfkfGV4zZE",
    "outputId": "e33ccec1-054c-4d35-e274-255b6e2b2847"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\Users\\tara0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     D:\\Users\\tara0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "D:\\Users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import layer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data Preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e9f4cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "20e9f4cf",
    "outputId": "764b0c16-94aa-4339-ec2c-c917820eb32e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287114it [02:59, 1598.72it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
       "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
       "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A drunk driver who killed a young woman in a h...</td>\n",
       "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
       "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
       "2  A drunk driver who killed a young woman in a h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Bishop John Folda, of North Dakota, is taking ...  \n",
       "1  Criminal complaint: Cop used his role to help ...  \n",
       "2  Craig Eccleston-Todd, 27, had drunk at least t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tqdm() as bar:\n",
    "    train_df = pd.read_csv('cnn_dailymail/train.csv', skiprows=lambda x: bar.update(1) and False)\n",
    "train_df.pop('id')\n",
    "train_df.head(3)\n",
    "#train_df = train_df[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d338fad6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d338fad6",
    "outputId": "351986a7-4eb1-490f-897f-ab51f33da7e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287113\n",
      "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
      "Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\n",
      "He contracted the infection through contaminated food in Italy .\n",
      "Church members in Fargo, Grand Forks and Jamestown could have been exposed .\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(train_df['article'][0])\n",
    "print(train_df['highlights'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0cecef",
   "metadata": {
    "id": "5c0cecef"
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\\\n",
    "                       \"can't\": \"cannot\", \"'cause\": \"because\",\\\n",
    "                       \"could've\": \"could have\", \\\n",
    "                       \"couldn't\": \"could not\",\"didn't\": \"did not\",\\\n",
    "                       \"doesn't\": \"does not\", \"don't\": \"do not\",\\\n",
    "                       \"hadn't\": \"had not\", \"hasn't\": \"has not\",\\\n",
    "                       \"haven't\": \"have not\",\"he'd\": \"he would\",\\\n",
    "                       \"he'll\": \"he will\", \"he's\": \"he is\", \\\n",
    "                       \"how'd\": \"how did\", \"how'd'y\": \"how do you\",\\\n",
    "                       \"how'll\": \"how will\", \"how's\": \"how is\",\\\n",
    "                       \"I'd\": \"I would\", \"I'd've\": \"I would have\", \\\n",
    "                       \"I'll\": \"I will\", \"I'll've\": \"I will have\",\\\n",
    "                       \"I'm\": \"I am\", \"I've\": \"I have\", \\\n",
    "                       \"i'd\": \"i would\",\"i'd've\": \"i would have\",\\\n",
    "                       \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\\\n",
    "                       \"i'm\": \"i am\", \"i've\": \"i have\", \\\n",
    "                       \"isn't\": \"is not\", \"it'd\": \"it would\",\\\n",
    "                       \"it'd've\": \"it would have\", \"it'll\": \"it will\",\\\n",
    "                       \"it'll've\": \"it will have\",\"it's\": \"it is\",\\\n",
    "                       \"let's\": \"let us\", \"ma'am\": \"madam\",\\\n",
    "                       \"mayn't\": \"may not\", \"might've\": \"might have\",\\\n",
    "                       \"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\\\n",
    "                       \"must've\": \"must have\",\"mustn't\": \"must not\",\\\n",
    "                       \"mustn't've\": \"must not have\",\\\n",
    "                       \"needn't\": \"need not\", \"needn't've\": \"need not have\",\\\n",
    "                       \"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\\\n",
    "                       \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\\\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\\\n",
    "                       \"she'd\": \"she would\", \"she'd've\": \"she would have\",\\\n",
    "                       \"she'll\": \"she will\", \"she'll've\": \"she will have\",\\\n",
    "                       \"she's\": \"she is\",\"should've\": \"should have\",\\\n",
    "                       \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\\\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\",\"this's\": \"this is\",\\\n",
    "                       \"that'd\": \"that would\", \"that'd've\": \"that would have\",\\\n",
    "                       \"that's\": \"that is\", \"there'd\": \"there would\",\\\n",
    "                       \"there'd've\": \"there would have\", \"there's\": \"there is\",\\\n",
    "                       \"here's\": \"here is\",\"they'd\": \"they would\",\\\n",
    "                       \"they'd've\": \"they would have\",\"they'll\": \"they will\",\\\n",
    "                       \"they'll've\": \"they will have\", \"they're\": \"they are\",\\\n",
    "                       \"they've\": \"they have\", \"to've\": \"to have\",\\\n",
    "                       \"wasn't\": \"was not\", \"we'd\": \"we would\",\\\n",
    "                       \"we'd've\": \"we would have\", \"we'll\": \"we will\",\\\n",
    "                       \"we'll've\": \"we will have\", \"we're\": \"we are\",\\\n",
    "                       \"we've\": \"we have\", \"weren't\": \"were not\", \\\n",
    "                       \"what'll\": \"what will\", \"what'll've\": \"what will have\",\\\n",
    "                       \"what're\": \"what are\",\"what's\": \"what is\",\\\n",
    "                       \"what've\": \"what have\", \"when's\": \"when is\",\\\n",
    "                       \"when've\": \"when have\", \"where'd\": \"where did\",\\\n",
    "                       \"where's\": \"where is\",\"where've\": \"where have\",\\\n",
    "                       \"who'll\": \"who will\", \"who'll've\": \"who will have\",\\\n",
    "                       \"who's\": \"who is\", \"who've\": \"who have\",\\\n",
    "                       \"why's\": \"why is\", \"why've\": \"why have\",\\\n",
    "                       \"will've\": \"will have\", \"won't\": \"will not\",\\\n",
    "                       \"won't've\": \"will not have\",\"would've\": \"would have\",\\\n",
    "                       \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\\\n",
    "                       \"y'all\": \"you all\",\"y'all'd\": \"you all would\",\\\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\\\n",
    "                       \"y'all've\": \"you all have\",\"you'd\": \"you would\",\\\n",
    "                       \"you'd've\": \"you would have\", \"you'll\": \"you will\",\\\n",
    "                       \"you'll've\": \"you will have\",\"you're\": \"you are\",\\\n",
    "                       \"you've\": \"you have\"}\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    sentences = []\n",
    "    \n",
    "    for sentence in tqdm(text):\n",
    "        # Lowercase\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # Remove word between () and []\n",
    "        sentence = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sentence)\n",
    "\n",
    "        # Transforming contraction\n",
    "        sent = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word in contraction_mapping:\n",
    "                sent.append(contraction_mapping[word])\n",
    "            else:\n",
    "                sent.append(word)\n",
    "        sentence = ' '.join(sent) \n",
    "\n",
    "        # Removing apostrophe\n",
    "        sentence = re.sub(r\"'s\\b\",\"\",sentence)\n",
    "\n",
    "        # Removing special characters \n",
    "        sentence = re.sub(\"[^a-zA-Z0-9]\", \" \", sentence)\n",
    "        sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence, flags=re.MULTILINE)\n",
    "        sentence = re.sub(r'\\<a href', ' ', sentence)\n",
    "        sentence = re.sub(r'&amp;', '', sentence) \n",
    "        sentence = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', sentence)\n",
    "        sentence = re.sub(r'<br />', ' ', sentence)\n",
    "        sentence = re.sub(r'\\'', ' ', sentence)\n",
    "        \n",
    "        \n",
    "        #sentence = ' '.join([contraction_mapping[t] if t in contraction_mapping      else t for t in sentence.split(\" \")])\n",
    "        # Remove stop words\n",
    "        \"\"\"sent = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in stop_words:\n",
    "                sent.append(word)            \n",
    "        sent = ' '.join(sent)\"\"\" \n",
    "\n",
    "        # Remove short words\n",
    "        \"\"\"sent = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            if len(word)>3:\n",
    "                sent.append(word)\n",
    "        sentence = ' '.join(sent) \"\"\"\n",
    "\n",
    "        #sentences.append(word_tokenize(sentence))\n",
    "        sentence = re.sub(\"\\n\", '', sentence)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N8BW_41SiipG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8BW_41SiipG",
    "outputId": "1e03fcf4-7825-4ddc-a49d-2ccf2552f70a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5ac65b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de5ac65b",
    "outputId": "d397a7e0-7ad9-47e8-a973-47cac729d044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5956/5956 [00:01<00:00, 5677.76it/s]\n",
      "100%|██████████| 5956/5956 [00:00<00:00, 23729.27it/s]\n",
      "100%|██████████| 5956/5956 [00:00<00:00, 29929.52it/s]\n",
      "100%|██████████| 5956/5956 [00:00<00:00, 110306.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located\n",
      "['by', 'associated', 'press', 'published', '14', '11', 'est', '25', 'october', '2013', 'updated', '15', '36', 'est', '25', 'october', '2013', 'the', 'bishop', 'of', 'the', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'has', 'exposed', 'potentially', 'hundreds', 'of', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'to', 'the', 'hepatitis', 'a', 'virus', 'in', 'late', 'september', 'and', 'early', 'october', 'the', 'state', 'health', 'department', 'has', 'issued', 'an', 'advisory', 'of', 'exposure', 'for', 'anyone', 'who', 'attended', 'five', 'churches', 'and', 'took', 'communion', 'bishop', 'john', 'folda', 'of', 'the', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'has', 'exposed', 'potentially', 'hundreds', 'of', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'to', 'the', 'hepatitis', 'a', 'state', 'immunization', 'program', 'manager', 'molly', 'howell', 'says', 'the', 'risk', 'is', 'low', 'but', 'officials', 'feel', 'it', 'is', 'important', 'to', 'alert', 'people', 'to', 'the', 'possible', 'exposure', 'the', 'diocese', 'announced', 'on', 'monday', 'that', 'bishop', 'john', 'folda', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'with', 'hepatitis', 'a', 'the', 'diocese', 'says', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'while', 'attending', 'a', 'conference', 'for', 'newly', 'ordained', 'bishops', 'in', 'italy', 'last', 'month', 'symptoms', 'of', 'hepatitis', 'a', 'include', 'fever', 'tiredness', 'loss', 'of', 'appetite', 'nausea', 'and', 'abdominal', 'discomfort', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'is', 'where', 'the', 'bishop', 'is', 'located']\n",
      "bishop john folda of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand forks and jamestown could have been exposed\n",
      "['bishop', 'john', 'folda', 'of', 'north', 'dakota', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'in', 'italy', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'could', 'have', 'been', 'exposed']\n",
      "by associated press published 14 11 est 25 october 2013 updated 15 36 est 25 october 2013 the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located\n",
      "bishop john folda of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand forks and jamestown could have been exposed\n",
      "5956\n",
      "5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = clean_text(train)\n",
    "\n",
    "\n",
    "# Remove double space\n",
    "temp = []\n",
    "for sentence in tqdm(train):\n",
    "    s_temp = []\n",
    "    for word in sentence.split(' '):\n",
    "        if word != '':\n",
    "            s_temp.append(word)\n",
    "    temp.append(s_temp)\n",
    "    del s_temp\n",
    "\n",
    "train = []\n",
    "for i in temp:\n",
    "    train.append(' '.join(i))\n",
    "\n",
    "del temp\n",
    "del train_df['article']\n",
    "\n",
    "highlights = clean_text(highlights)\n",
    "\n",
    "temp = []\n",
    "for sentence in tqdm(highlights):\n",
    "    s_temp = []\n",
    "    for word in sentence.split(' '):\n",
    "        if word != '':\n",
    "            s_temp.append(word)\n",
    "    temp.append(s_temp)\n",
    "    del s_temp\n",
    "\n",
    "highlights = []\n",
    "for i in temp:\n",
    "    highlights.append(' '.join(i))\n",
    "    \n",
    "del temp\n",
    "del train_df['highlights']\n",
    "#yo = ' '.join(temp)    \n",
    "print(train[0])\n",
    "print(train[0].split(\" \"))\n",
    "print(highlights[0])\n",
    "print(highlights[0].split(\" \"))\n",
    "\n",
    "\n",
    "print(train[0])\n",
    "print(highlights[0])\n",
    "\n",
    "print(len(train))\n",
    "print(len(highlights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d5fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 21530.73it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 255053.51it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "highlights_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in tqdm(train):\n",
    "    temp=i.split()\n",
    "    text_word_count.append(len(temp))\n",
    "\n",
    "for j in tqdm(highlights):\n",
    "    temp1=j.split()\n",
    "    highlights_word_count.append(len(temp1))\n",
    "\n",
    "\"\"\"length_df = pd.DataFrame({'text':text_word_count, 'headline':headline_word_count})\n",
    "length_df.hist(bins = 30,range=[0,1000])\"\"\"\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.hist(text_word_count, bins=20)\n",
    "plt.subplot(212)\n",
    "plt.hist(highlights_word_count, bins=20)\n",
    "plt.show()\n",
    "\n",
    "del text_word_count\n",
    "del highlights_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c866e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\tara0\\AppData\\Local\\Temp\\ipykernel_3528\\2961030213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mmaxlen_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mcnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# We can see that most of the highlights \n",
    "# and text lenth are in those range\n",
    "maxlen_text = 200\n",
    "MAX_LENGTH = maxlen_text\n",
    "maxlen_summ = 50\n",
    "\n",
    "cnt=0\n",
    "for i in train:\n",
    "    if(len(i.split())<=maxlen_text):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(train))\n",
    "\n",
    "cnt=0\n",
    "for i in highlights:\n",
    "    if(len(i.split())<=maxlen_summ):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(train))\n",
    "\n",
    "cnt=0\n",
    "for i in range(len(highlights)):\n",
    "    if(len(highlights[i].split())<=maxlen_summ and len(train[i].split())<=maxlen_text):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f4f167",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12f4f167",
    "outputId": "daa6e2b0-5241-406a-ab3a-b67a29a266fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287113/287113 [00:17<00:00, 16828.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5956\n",
      "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
      "5956\n",
      "5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- We only keep the corresponding dataset ---\n",
    "# 50/150 for fast training\n",
    "# 75/ 1000 for 75% of the dataset\n",
    "maxlen_text = 200\n",
    "MAX_LENGTH = maxlen_text\n",
    "maxlen_summ = 50\n",
    "new_train = []\n",
    "new_highlights = []\n",
    "\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    if len(train_df['highlights'][i].split())<=maxlen_summ and len(train_df['article'][i].split())<=MAX_LENGTH:\n",
    "        new_train.append(train_df['article'][i])\n",
    "        new_highlights.append(train_df['highlights'][i])\n",
    "\n",
    "print(len(train))\n",
    "print(len(new_train))\n",
    "print(new_train[0])\n",
    "\n",
    "\"\"\"del train\n",
    "del highlights\"\"\"\n",
    "\n",
    "train = new_train\n",
    "highlights = new_highlights\n",
    "\n",
    "print(len(train))\n",
    "print(len(highlights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_xf22i_s7KVO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xf22i_s7KVO",
    "outputId": "1fe367f3-393f-422f-ce0f-41a607461b33"
   },
   "outputs": [],
   "source": [
    "\"\"\"# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,t_train,highlights,t_highlights=train_test_split(train,highlights,test_size=0.3,random_state=0,shuffle=True) \n",
    "\n",
    "print(len(train))\n",
    "print(len(t_train))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dctVr1p79CWl",
   "metadata": {
    "id": "dctVr1p79CWl"
   },
   "outputs": [],
   "source": [
    "# 3 variables\n",
    "# input_lang, output_lang and pairs\n",
    "# PrepareData -> readLand       \n",
    "#             -> .addSentence\n",
    "#\n",
    "# readLand -> create Land for input and output and create pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ve1BCWzI-DXY",
   "metadata": {
    "id": "ve1BCWzI-DXY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e211bcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e211bcf",
    "outputId": "645e5b3b-e1b9-4fdf-8be1-b6a5bb63f47f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5956/5956 [00:04<00:00, 1326.59it/s]\n",
      "100%|██████████| 5956/5956 [00:16<00:00, 362.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'associated', 'press', 'published', '14', '11', 'est', '25', 'october', '2013', 'updated', '15', '36', 'est', '25', 'october', '2013', 'the', 'bishop', 'of', 'the', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'has', 'exposed', 'potentially', 'hundreds', 'of', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'to', 'the', 'hepatitis', 'a', 'virus', 'in', 'late', 'september', 'and', 'early', 'october', 'the', 'state', 'health', 'department', 'has', 'issued', 'an', 'advisory', 'of', 'exposure', 'for', 'anyone', 'who', 'attended', 'five', 'churches', 'and', 'took', 'communion', 'bishop', 'john', 'folda', 'of', 'the', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'has', 'exposed', 'potentially', 'hundreds', 'of', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'to', 'the', 'hepatitis', 'a', 'state', 'immunization', 'program', 'manager', 'molly', 'howell', 'says', 'the', 'risk', 'is', 'low', 'but', 'officials', 'feel', 'it', 'is', 'important', 'to', 'alert', 'people', 'to', 'the', 'possible', 'exposure', 'the', 'diocese', 'announced', 'on', 'monday', 'that', 'bishop', 'john', 'folda', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'with', 'hepatitis', 'a', 'the', 'diocese', 'says', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'while', 'attending', 'a', 'conference', 'for', 'newly', 'ordained', 'bishops', 'in', 'italy', 'last', 'month', 'symptoms', 'of', 'hepatitis', 'a', 'include', 'fever', 'tiredness', 'loss', 'of', 'appetite', 'nausea', 'and', 'abdominal', 'discomfort', 'fargo', 'catholic', 'diocese', 'in', 'north', 'dakota', 'is', 'where', 'the', 'bishop', 'is', 'located', '<EOS>']\n",
      "['bishop', 'john', 'folda', 'of', 'north', 'dakota', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'in', 'italy', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'could', 'have', 'been', 'exposed', '<EOS>']\n",
      "5956\n",
      "5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add Start and End tokens\n",
    "train_input = []\n",
    "train_target = []\n",
    "i=0\n",
    "for sentence in tqdm(train):\n",
    "    train_input.append(word_tokenize(sentence))\n",
    "    \"\"\"print(i)\n",
    "    if i == 547 or i == 548 or i == 549:\n",
    "        print(word_tokenize(sentence))\n",
    "        print(sentence)\n",
    "    i+=1\"\"\"\n",
    "    \n",
    "    \n",
    "for sentence in tqdm(highlights):\n",
    "    #sentence = \"<SOS>\" + sentence + \"<EOS>\"\n",
    "    train_target.append(word_tokenize(sentence))\n",
    "\n",
    "# Add start and end tokens\n",
    "for sentence in train_input:\n",
    "    #sentence.insert(0,'<SOS>')\n",
    "    sentence.append('<EOS>')\n",
    "for sentence in train_target:\n",
    "    #sentence.insert(0,'<SOS>')\n",
    "    sentence.append('<EOS>')\n",
    "    \n",
    "print(train_input[0])\n",
    "print(train_target[0])\n",
    "print(len(train_input))\n",
    "print(len(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gj67rR8eC_jM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj67rR8eC_jM",
    "outputId": "7264a8bc-b45f-44b0-e0c8-b22ea469e224"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a796901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a796901",
    "outputId": "8c79c1f9-d1f5-4bdc-974e-e64b333ccd19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38446\n",
      "19177\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {'text': {'<SOS>':0, '<EOS>':1}, 'highlights': {'<SOS>':0, '<EOS>':1}}\n",
    "ix_to_word = {'text': {0: '<SOS>', 1:'<EOS>'}, 'highlights': {0: '<SOS>', 1:'<EOS>'}}\n",
    "num_unique_words = 2\n",
    "# Create a dict of unique number for each unique word\n",
    "for sent in train_input:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix['text']:\n",
    "            word_to_ix['text'][word] = num_unique_words\n",
    "            ix_to_word['text'][num_unique_words] = word\n",
    "            num_unique_words += 1\n",
    "num_unique_words = 2\n",
    "for sent in train_target:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix['highlights']:\n",
    "            word_to_ix['highlights'][word] = num_unique_words\n",
    "            ix_to_word['highlights'][num_unique_words] = word\n",
    "            num_unique_words += 1\n",
    "            \n",
    "#print(word_to_ix)\n",
    "#print(word_to_ix['text'])\n",
    "#print(word_to_ix['highlights'])\n",
    "print(len(word_to_ix['text']))\n",
    "print(len(word_to_ix['highlights']))\n",
    "#print(ix_to_word)\n",
    "del train\n",
    "train = []\n",
    "for sentence in train_input:\n",
    "    train.append(' '.join(sentence))\n",
    "\n",
    "del highlights \n",
    "highlights = []\n",
    "for sentence in train_target:\n",
    "    highlights.append(' '.join(sentence))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8U6_k5DEGsHa",
   "metadata": {
    "id": "8U6_k5DEGsHa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4df9fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "c4df9fa4",
    "outputId": "d1a4f8ca-8bf2-4a00-e203-4676f70cec56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4169\n",
      "4169\n",
      "1787\n",
      "1787\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,t_train,highlights,t_highlights=train_test_split(train,highlights,test_size=0.3,random_state=0,shuffle=True) \n",
    "\n",
    "print(len(train))\n",
    "print(len(highlights))\n",
    "print(len(t_train))\n",
    "print(len(t_highlights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff0ed4",
   "metadata": {
    "id": "a9ff0ed4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1e189",
   "metadata": {
    "id": "98d1e189",
    "outputId": "5243339a-122b-408a-d466-9c72c81acd60"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8107da1",
   "metadata": {
    "id": "c8107da1"
   },
   "outputs": [],
   "source": [
    "# Model taken from Pytorch\n",
    "# https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden = hidden_size\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    # Forward function\n",
    "    def forward(self, input, hidden):\n",
    "        embed = self.embed(input).view(1,1,-1)\n",
    "        output = embed\n",
    "        # Get result from gru\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden, device=device)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden = hidden_size\n",
    "        self.embed = nn.Embeddingt(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    # Forward function\n",
    "    def forward(self, input, hidden):\n",
    "        embed = self.embed(input).view(1,1,-1)\n",
    "        output = F.relu(embed)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.linear(output[0])\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size, device=device)\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        #print(\"You guys called me ?\")\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "343ab6e9",
   "metadata": {
    "id": "343ab6e9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96670ab",
   "metadata": {
    "id": "f96670ab"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "def training(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            #print(\"Test1\")\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            #print(\"Test2\")\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # Teacher forcing\n",
    "            decoder_input = target_tensor[di]  \n",
    "            \n",
    "    \n",
    "    else:\n",
    "        # Without teacher forcing\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach() \n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == 1:\n",
    "                break\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def test(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \"\"\"\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \"\"\"\n",
    "    loss_total = 0\n",
    "    ITE = 10\n",
    "    testing_pairs = [tensorsFromPair(random.choice(t_pairs))\n",
    "                      for i in tqdm(range(ITE))]\n",
    "    \n",
    "    for i in range(0, len(testing_pairs)):\n",
    "    \n",
    "        testing_pair = testing_pairs[i - 1]\n",
    "        input_tensor = testing_pair[0]\n",
    "        target_tensor = testing_pair[1]\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        \n",
    "        if(input_length > MAX_LENGTH):\n",
    "            print(input_length)\n",
    "            ITE -= 1\n",
    "            continue\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden, device=device)\n",
    "\n",
    "        loss = 0\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == 1:\n",
    "                break\n",
    "                \n",
    "        loss_total += loss.item() / target_length\n",
    "\n",
    "    return loss_total / ITE\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, test_every=100, learning_rate=0.01):\n",
    "    print(\"Training...\")\n",
    "    print(\"Will print every: \" + str(print_every))\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    losses_av = []\n",
    "    test_loss = []\n",
    "    ITE = print_every\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print(\"Taking random pairs\")\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in tqdm(range(n_iters))]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    print(\"Start Training...\")\n",
    "    for i in tqdm(range(1, n_iters + 1)):\n",
    "        if i % 1000 == 0:\n",
    "            print(i,\"/\",n_iters + 1)\n",
    "        \n",
    "        training_pair = training_pairs[i - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        input_length = input_tensor.size(0)\n",
    "        if(input_length > MAX_LENGTH):\n",
    "            print(input_length)\n",
    "            continue\n",
    "        loss = training(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        #losses.append(loss)\n",
    "        if i % print_every == 0:\n",
    "            print(\"we print\")\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            losses_av.append(print_loss_avg)\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, i / n_iters),\n",
    "                                         i, i / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if i % test_every == 0:\n",
    "            print(\"We test\")\n",
    "            test_loss.append(test(encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion))\n",
    "\n",
    "    return losses, losses_av, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47112ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "b47112ae",
    "outputId": "c9d5f29a-3c7a-4bc1-8ce7-df79ffc5b69c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ad86ef",
   "metadata": {
    "id": "06ad86ef"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(id, sentence):    \n",
    "    #print(id)\n",
    "    #print(word_to_ix[id])\n",
    "    return [word_to_ix[id][word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(id, sentence):\n",
    "    #print(sentence)\n",
    "    indexes = indexesFromSentence(id, sentence)\n",
    "    #print(indexes)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    #print(\" -- Pair --\")\n",
    "    input_tensor = tensorFromSentence('text', pair[0])\n",
    "    target_tensor = tensorFromSentence('highlights', pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b46cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the Data\n",
      "4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4169/4169 [00:00<00:00, 1041580.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the Data\n",
      "1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1787/1787 [00:00<00:00, 894097.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4169\n",
      "1787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "    \n",
    "# Create the Pairs\n",
    "print(\"Preparing the Data\")\n",
    "print(len(train))\n",
    "for i in tqdm(range(len(train))):\n",
    "    pairs.append([train[i], highlights[i]])\n",
    "\n",
    "del train\n",
    "del highlights\n",
    "\n",
    "t_pairs = []\n",
    "# Create the Test Pairs\n",
    "print(\"Preparing the Data\")\n",
    "print(len(t_train))\n",
    "for i in tqdm(range(len(t_train))):\n",
    "    t_pairs.append([t_train[i], t_highlights[i]])\n",
    "\n",
    "del t_train\n",
    "del t_highlights\n",
    "\n",
    "print(len(pairs))\n",
    "print(len(t_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b38048b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b38048b",
    "outputId": "c4476854-87bc-495b-cbf8-a0d402796fb0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "Will print every: 99\n",
      "Taking random pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 7874.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:02<41:06,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:09<30:16,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/1000 [01:09<45:54,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1000 [01:43<41:57,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 67/1000 [02:53<42:13,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1000 [02:59<35:30,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 98/1000 [04:08<39:59,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "4m 11s (- 38m 6s) (99 9%) 8.8358\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 4996.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 99/1000 [04:12<45:16,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 108/1000 [04:30<35:47,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [06:21<38:43,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 166/1000 [06:55<36:21,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 194/1000 [08:02<30:53,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 197/1000 [08:06<26:09,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "8m 8s (- 32m 59s) (198 19%) 8.9797\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 3334.90it/s]\n",
      " 21%|██        | 206/1000 [08:31<35:44,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 209/1000 [08:36<30:28,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 262/1000 [10:40<29:31,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 296/1000 [11:59<28:09,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "12m 1s (- 28m 27s) (297 29%) 8.7674\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 2498.69it/s]\n",
      " 38%|███▊      | 377/1000 [15:14<26:13,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [15:22<23:28,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 388/1000 [15:37<23:48,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 395/1000 [15:51<22:59,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "15m 54s (- 24m 15s) (396 39%) 8.3132\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 3333.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 396/1000 [15:55<26:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 437/1000 [17:38<23:27,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 461/1000 [18:36<24:11,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 467/1000 [18:49<22:40,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 478/1000 [19:14<21:52,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 494/1000 [19:55<23:47,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "19m 57s (- 20m 21s) (495 49%) 7.9695\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 2499.88it/s]\n",
      " 52%|█████▏    | 520/1000 [21:00<20:50,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 593/1000 [24:03<18:29,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "24m 6s (- 16m 28s) (594 59%) 8.0974\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 2498.84it/s]\n",
      " 61%|██████    | 611/1000 [24:55<18:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 614/1000 [25:00<14:29,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 670/1000 [27:10<13:22,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 672/1000 [27:12<10:12,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 692/1000 [27:56<11:40,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "27m 58s (- 12m 23s) (693 69%) 7.5666\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 1666.59it/s]\n",
      " 69%|██████▉   | 693/1000 [27:59<12:43,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 780/1000 [31:07<07:08,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 791/1000 [31:32<09:36,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "31m 35s (- 8m 17s) (792 79%) 7.5843\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 769.22it/s]\n",
      " 82%|████████▏ | 818/1000 [32:40<08:26,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 889/1000 [35:17<04:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "we print\n",
      "35m 20s (- 4m 19s) (891 89%) 7.7543\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 909.16it/s]\n",
      " 90%|████████▉ | 897/1000 [35:33<03:37,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [35:38<03:04,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 912/1000 [36:02<03:03,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 928/1000 [36:34<02:44,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 983/1000 [38:37<00:41,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 989/1000 [38:49<00:25,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we print\n",
      "38m 51s (- 0m 23s) (990 99%) 7.3939\n",
      "We test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 1428.72it/s]\n",
      "100%|█████████▉| 999/1000 [39:12<00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [39:15<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#MAX_LENGTH = 1000\n",
    "hidden_size = 100\n",
    "#print(word_to_ix['highlights'])\n",
    "#print(len(word_to_ix['highlights']))\n",
    "# input_lang.n_words -> input size (total number of words)\n",
    "#                       size of word_to_ix\n",
    "# output_lang.n_words -> output size (same ? or different ?) \n",
    "#                        or maybe we need word_to_ix for summary ?\n",
    "encoder1 = Encoder(len(word_to_ix['text']), hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, len(word_to_ix['highlights']), dropout_p=0.1).to(device)\n",
    "\n",
    "\n",
    "loss, loss_av, loss_test = trainIters(encoder1, attn_decoder1, 1000, print_every=99, test_every=99, learning_rate = 0.001)\n",
    "#print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "IOEp5y1LF4Q2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOEp5y1LF4Q2",
    "outputId": "1fa00986-d47e-4515-b986-c2ee60ba5cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[]\n",
      "[8.835751152570577, 8.979719875029785, 8.767371396594816, 8.313158185505555, 7.96952322387171, 8.097437258579772, 7.5665912096233825, 7.5843387352919125, 7.754267375214157, 7.3938734656506435]\n",
      "[9.732592707485182, 9.277452112503251, 8.620137457107779, 8.356992515697728, 8.35868811676437, 8.008977719153132, 1.396952941618648, 7.994316138989288, 8.097803267164132, 7.9263817451541625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(MAX_LENGTH)\n",
    "print(loss)\n",
    "print(loss_av)\n",
    "print(loss_test)\n",
    "\n",
    "\"\"\"import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\"\"\"\n",
    "\"\"\"plt.plot(loss_av)\n",
    "plt.plot(loss_test)\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\"\"\"torch.save(encoder1.state_dict(), \"encoder1_same_output.pt\")\n",
    "torch.save(attn_decoder1.state_dict(), \"attn_decoder1_same_output.pt\")\"\"\"\n",
    "\n",
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17ee2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence('text', sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[0]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == 1:\n",
    "                decoded_words.append('.')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ix_to_word['highlights'][topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1504ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandom(encoder, decoder, n=5):\n",
    "    text=list()\n",
    "    highlights=list()\n",
    "    pre_highlights=list()    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "\n",
    "        if(len(pair[0].split())>=MAX_LENGTH):\n",
    "            continue\n",
    "        else:\n",
    "            if(i%10==0):\n",
    "                print(i*100/n,\"% complete\")\n",
    "            \n",
    "            # We get our text and real highlights (summary)\n",
    "            text.append(pair[0])\n",
    "            highlights.append(pair[1])\n",
    "            \n",
    "            # Get prediction\n",
    "            output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "            output_sentence = ' '.join(output_words)\n",
    "            pre_highlights.append(output_sentence)\n",
    "\n",
    "    return text,highlights,pre_highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b20ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete\n",
      "20.0 % complete\n",
      "40.0 % complete\n",
      "60.0 % complete\n",
      "80.0 % complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"pairs = []\n",
    "    \n",
    "# Create the Pairs\n",
    "print(\"Preparing the Data\")\n",
    "for i in range(len(train)):\n",
    "    pairs.append([train[i], highlights[i]])\"\"\"\n",
    "\n",
    "text,highlights,pre_highlights=evaluateRandomly(encoder1, attn_decoder1,50)\n",
    "\n",
    "prev=pd.DataFrame()\n",
    "\n",
    "prev['text']=text\n",
    "prev['highlights']=highlights\n",
    "prev['pre_highlights']=pre_highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "494f46d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "january 18 2013 download a pdf map related to today show washington d c click here to access the transcript of today cnn student news program please note that there may be a delay between the time when the video is available and when the transcript is published <EOS>\n",
      "the daily transcript is a written version of each day cnn student news program use this transcript to help students with reading comprehension and vocabulary use the weekly newsquiz to test your knowledge of stories you saw on cnn student news <EOS>\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "-----\n",
      "video producer note you have heard of 3 d printing the process of using a specialized printer to create real world objects from computer models now there is something new on the horizon that could revolutionize this burgeoning technology 4 d printing at ted 2013 senior fellow skylar tibbits sat down with cnn ideas to further explain this mysterious fourth dimension in printing technology he also provided us with visual examples from his self assembly lab mit see how it all works in the video above what uses do you see for 4 d printing if any <EOS>\n",
      "skylar tibbits spoke at ted 2013 about 4 d printing tibbits the idea behind 4 d printing is to have change over time 4 d printing could create robotics without wires or motors <EOS>\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "-----\n",
      "a military contractor plane crashed wednesday upon approach to a navy air base in southern california killing the sole person aboard the aircraft operated by the airborne tactical advantage company went down as it was nearing naval base ventura county in oxnard about halfway between the coastal cities of santa barbara and santa monica capt mike lindberry a spokesman for the ventura county fire department tweeted it is not known whether the hunter hawker aircraft pilot ejected or if chute was part of debris field atac flies small jets used in exercises at the navy base according to base spokeswoman kimberly gearhart she said that the contractor leases space on the base naval base ventura county was established in 2000 combining two world war ii era locales in naval air station point mugu and construction battalion center port hueneme it is now home to more than 80 military commands according to the base website cnn j r nichols and mayra cuevas contributed to this report <EOS>\n",
      "a hunter hawker aircraft goes down near naval base ventura county in california it operated by airborne tactical advantage company which flies in military exercises it not known whether pilot ejected or whether the chute was part of the debris field <EOS>\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "-----\n",
      "sepp blatter has confirmed he will stand for a fifth term as fifa president next year blatter has been widely expected to stand again despite saying in 2011 this would be his last term and now he has confirmed he will do so it follows uefa president michel platini announcing last month that he would not stand for the fifa post change of mind sepp blatter has confirmed he will stand for a fifth term as fifa president next year out the running uefa president michel platini will not challenge blatter for the high profile position blatter said he would officially inform the fifa executive committee of his plans at the next meeting on september 25 and 26 the 78 year old said in a video interview played at the soccerex conference in manchester i will inform the executive committee it a question of respect also to say then to the football family yes i will be ready i will be a candidate you see a mission is never finished and my mission is not finished <EOS>\n",
      "the current fifa president originally said he was planing to step down however sepp blatter has decided he wants to stand for another election michel platini announced last month that he would not stand for fifa post <EOS>\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "-----\n",
      "when temperatures plunge most people head straight indoors not for the residents of donetsk in ukraine several daring locals took to the ice cold waters of the city s frozen ponds over the weekend marking the start of the eleventh season of ice swimming diving into the ice cold water of scherbakov park second city pond participants performed comedy fairy tale sketches and danced to traditional folk music such is the tradition of swimming in the icy waters that even several members from the donetsk peoples republic national council joined in several daring locals took to the ice cold waters of donetsk s frozen ponds over the weekend marking the start of the eleventh season of ice swimming taking place annually in ukraine the brave bathers swim in temperatures between 2 to 4 c diving into the ice cold water of scherbakov park s second city pond participants performed comedy fairy tale sketches and danced to traditional folk music taking place annually the brave bathers swim in temperatures between 2 to 4 c the pastime is considered to be good for blood circulation muscle soreness and respiratory problems <EOS>\n",
      "locals gathered at scherbakov park to dive into the icey waters taking place annually bathers swim in temperatures between 2 to 4 c considered to be good for blood circulation and respiratory problems politicians from the donetsk peoples republic national council joined in <EOS>\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(prev['text'][i])\n",
    "    print(prev['highlights'][i])\n",
    "    print(prev['pre_highlights'][i])\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e2374de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "  6%|▋         | 3/48 [00:00<00:01, 29.41it/s]It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      " 83%|████████▎ | 40/48 [00:00<00:00, 225.49it/s]It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "100%|██████████| 48/48 [00:00<00:00, 217.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001350937696477946"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BLEU SCORE\n",
    "\n",
    "#!pip install sacrebleu\n",
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "bleu = BLEU()\n",
    "\n",
    "b = 0\n",
    "for i in tqdm(range(len(prev))):\n",
    "    b = b + bleu.sentence_score(\n",
    "      hypothesis=prev['pre_highlights'][i],\n",
    "      references=[prev['highlights'][i]],\n",
    "  ).score\n",
    "\n",
    "\n",
    "b/(100*len(prev)) # sacreBLEU gives the score in percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a50f735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from rouge_score) (1.3.0)\n",
      "Requirement already satisfied: nltk in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: numpy in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from rouge_score) (1.21.6)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: joblib in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Requirement already satisfied: click in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from click->nltk->rouge_score) (1.7.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from click->nltk->rouge_score) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\users\\tara0\\anaconda3\\envs\\lign167\\lib\\site-packages (from importlib-metadata->click->nltk->rouge_score) (3.8.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=474f521db291440d568db0fe1fcf8865817f5d16c26b34d4fa6bacb7996ac712\n",
      "  Stored in directory: c:\\users\\tara0\\appdata\\local\\pip\\cache\\wheels\\8e\\6b\\70\\59daa7c90a238610e34bac5916e001fe3d9bb0ec59c8cf5518\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "{'rouge1': Score(precision=0.6111111111111112, recall=1.0, fmeasure=0.7586206896551725), 'rougeL': Score(precision=0.6111111111111112, recall=1.0, fmeasure=0.7586206896551725)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "r = []\n",
    "\n",
    "r.append(scorer.score('coast guard trying to contain the situation the cause under investigation',\n",
    "                      'coast guard trying to contain to the situation the cause under investigation the investigation is under to investigation'))\n",
    "\n",
    "#score[0][\"rouge-l\"][\"f\"]\n",
    "for rou in r:\n",
    "    print(rou)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss for Max_LENGTH: 150 and 6343 data for 15k epoch\n",
    "# [5.892520071259602, 5.610622926006175, 5.179409938791374, \n",
    "# 5.131760642713841, 4.950740275768066, 4.6816012215271305, \n",
    "# 8.409076439031164, 3.696371140073135, 3.4204536185173997, \n",
    "# 6.458611371819749, 2.93653876110649, 2.8217197387743456, \n",
    "# 2.7238554163704514]\n",
    "\n",
    "# Blue score\n",
    "# 0.23543882369040114\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef859ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_av)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(encoder, decoder, input):\n",
    "    text=list()\n",
    "    highlights=list()\n",
    "    pre_highlights=list()    \n",
    "    \n",
    "\n",
    "    if(len(input.split())>=150):\n",
    "        print(\"Text too long\")\n",
    "        \"\"\"continue\"\"\"\n",
    "    else:\n",
    "\n",
    "        # Get prediction\n",
    "        output_words, attentions = evaluate(encoder, decoder, input)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        pre_highlights.append(output_sentence)\n",
    "\n",
    "    return pre_highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"(CNN)A fiery greeted people in Washington Sunday. The deep caught native Tim eye. He photographed a handful of aerial shots of the city's and shared them on CNN iReport. The stunning were the result of in parts of\"\n",
    "input = clean_text([input])\n",
    "\n",
    "input = ' '.join(input)\n",
    "\n",
    "s_temp = []\n",
    "for word in input.split(' '):\n",
    "    if word != '':\n",
    "        s_temp.append(word)\n",
    "\n",
    "\n",
    "input = ' '.join(s_temp)\n",
    "\n",
    "\n",
    "print(input)\n",
    "\n",
    "#input = ' '.join(input)\n",
    "\n",
    "summarize(encoder1, attn_decoder1, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82440fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a39c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5.939325052948383, 5.4180154720227875, 5.421968410928943, 9.380419022352958, 4.250920068281035, 7.572154979216144, 3.3232256719957443, 2.896347552423162, 2.5066783530102246, 2.102867315766128, 1.6086884571465674, 1.4496897322876037, 1.1742980754223569]\n",
    "# 150/50\n",
    "# 15000\n",
    "# blue score; 0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bdb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
